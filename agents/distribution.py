import json
from datetime import datetime
from pathlib import Path
from typing import List

from .content import DraftArticle


class DistributionAgent:
    """
    Responsible for publishing validated articles to the static site,
    and keeping supporting artefacts like sitemap and RSS feed up to date.
    """

    def __init__(self, data_dir: Path, site_dir: Path, posts_dir: Path) -> None:
        self.data_dir = Path(data_dir)
        self.site_dir = Path(site_dir)
        self.posts_dir = Path(posts_dir)

    def _publish_article(self, draft: DraftArticle) -> Path:
        self.posts_dir.mkdir(parents=True, exist_ok=True)
        filename = f"{draft.slug}.md"
        path = self.posts_dir / filename

        front_matter = (
            "---\n"
            f"title: \"{draft.title}\"\n"
            f"date: {draft.created_at}\n"
            "layout: post\n"
            "---\n\n"
        )

        path.write_text(front_matter + draft.content + "\n", encoding="utf-8")
        return path

    def _load_posts_metadata(self) -> List[dict]:
        posts: List[dict] = []
        if not self.posts_dir.exists():
            return posts
        for file in sorted(self.posts_dir.glob("*.md")):
            text = file.read_text(encoding="utf-8")
            title_line = next((line for line in text.splitlines() if line.startswith("title: ")), None)
            title = title_line.split(":", 1)[1].strip().strip('"') if title_line else file.stem
            posts.append(
                {
                    "title": title,
                    "slug": file.stem,
                    "path": f"posts/{file.name}",
                    "date": datetime.utcfromtimestamp(file.stat().st_mtime).isoformat() + "Z",
                }
            )
        return posts

    def _update_index(self, posts: List[dict]) -> None:
        index = self.site_dir / "index.md"
        lines = [
            "# NeuralStack Autonomous Tech Insights",
            "",
            "Curated long-form guides on developer tooling, compatibility, and translated tech insight.",
            "",
            "## Latest posts",
            "",
        ]
        if not posts:
            lines.append("No posts have been published yet. Check back tomorrow.")
        else:
            for post in sorted(posts, key=lambda p: p["date"], reverse=True):
                lines.append(f"- [{post['title']}]({post['path']})  \n  _Updated {post['date']}_")

        index.write_text("\n".join(lines) + "\n", encoding="utf-8")

    def _update_sitemap(self, posts: List[dict]) -> None:
        sitemap = self.site_dir / "sitemap.xml"
        # URL structure assumes GitHub Pages with project site at /.
        base_url = "{{BASE_URL}}"
        urls = [f"{base_url}/"]
        urls += [f"{base_url}/{p['path']}" for p in posts]

        entries = []
        for url in urls:
            entries.append(
                "  <url>\n"
                f"    <loc>{url}</loc>\n"
                f"    <lastmod>{datetime.utcnow().date().isoformat()}</lastmod>\n"
                "    <changefreq>daily</changefreq>\n"
                "    <priority>0.7</priority>\n"
                "  </url>"
            )

        xml = (
            '<?xml version="1.0" encoding="UTF-8"?>\n'
            '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
            + "\n".join(entries)
            + "\n</urlset>\n"
        )
        sitemap.write_text(xml, encoding="utf-8")

    def _update_rss(self, posts: List[dict]) -> None:
        feed = self.site_dir / "feed.xml"
        base_url = "{{BASE_URL}}"
        items = []
        for post in sorted(posts, key=lambda p: p["date"], reverse=True):
            items.append(
                "  <item>\n"
                f"    <title>{post['title']}</title>\n"
                f"    <link>{base_url}/{post['path']}</link>\n"
                f"    <guid>{base_url}/{post['path']}</guid>\n"
                f"    <pubDate>{post['date']}</pubDate>\n"
                "    <description>Long-form technical guide generated by the autonomous pipeline.</description>\n"
                "  </item>"
            )

        xml = (
            '<?xml version="1.0" encoding="UTF-8"?>\n'
            "<rss version=\"2.0\">\n"
            " <channel>\n"
            "  <title>NeuralStack Autonomous Tech Insights</title>\n"
            f"  <link>{base_url}/</link>\n"
            "  <description>Daily long-form content on developer tooling and compatibility.</description>\n"
            + "\n".join(items)
            + "\n </channel>\n</rss>\n"
        )
        feed.write_text(xml, encoding="utf-8")

    def _update_performance_summary(self, published_paths: List[Path]) -> None:
        perf_file = self.data_dir / "performance.json"
        if not perf_file.exists():
            return
        try:
            data = json.loads(perf_file.read_text(encoding="utf-8"))
        except Exception:
            return
        data.setdefault("latest_published_files", [])
        data["latest_published_files"] = [str(p) for p in published_paths]
        perf_file.write_text(json.dumps(data, indent=2), encoding="utf-8")

    def _prepare_video_script_stub(self, draft: DraftArticle, output_dir: Path) -> None:
        """
        Optional: create a short-form video script outline that can later be used
        to record YouTube Shorts or similar content.
        """
        output_dir.mkdir(parents=True, exist_ok=True)
        path = output_dir / f"{draft.slug}-short-script.md"
        outline = (
            f"# Short video script for: {draft.title}\n\n"
            "## Hook (3–5 seconds)\n"
            "- State the core pain point in a single sharp sentence.\n\n"
            "## Context (5–10 seconds)\n"
            "- Mention who this is for and when it matters.\n\n"
            "## Key idea (10–20 seconds)\n"
            "- Summarise one concrete insight from the article.\n\n"
            "## Call to action (3–5 seconds)\n"
            "- Invite viewers to read the full guide on the site.\n"
        )
        path.write_text(outline, encoding="utf-8")

    def run(self, approved_drafts: List[DraftArticle]) -> List[Path]:
        published_paths: List[Path] = []
        for draft in approved_drafts:
            post_path = self._publish_article(draft)
            published_paths.append(post_path)
            self._prepare_video_script_stub(draft, self.data_dir / "video_scripts")

        posts_meta = self._load_posts_metadata()
        self._update_index(posts_meta)
        self._update_sitemap(posts_meta)
        self._update_rss(posts_meta)
        self._update_performance_summary(published_paths)
        return published_paths


__all__ = ["DistributionAgent"]

